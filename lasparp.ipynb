{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-09-18T14:45:50.186270Z",
     "iopub.status.busy": "2025-09-18T14:45:50.185885Z",
     "iopub.status.idle": "2025-09-18T14:45:54.836323Z",
     "shell.execute_reply": "2025-09-18T14:45:54.835472Z",
     "shell.execute_reply.started": "2025-09-18T14:45:50.186243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install required packages including torchcodec\n",
    "!pip install -q datasets==3.6.0 \\\n",
    "sentence-transformers==4.1.0 \\\n",
    "soundfile==0.13.1 \\\n",
    "speechbrain==1.0.3 \\\n",
    "torchaudio==2.6.0 \\\n",
    "transformers==4.52.4 \\\n",
    "torchcodec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:45:54.838122Z",
     "iopub.status.busy": "2025-09-18T14:45:54.837798Z",
     "iopub.status.idle": "2025-09-18T14:46:02.930870Z",
     "shell.execute_reply": "2025-09-18T14:46:02.930124Z",
     "shell.execute_reply.started": "2025-09-18T14:45:54.838086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "from datasets import load_dataset, Dataset as HFDataset  # Fixed import\n",
    "from huggingface_hub import login\n",
    "from speechbrain.inference import EncoderClassifier\n",
    "from google.colab import userdata\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# ===========================\n",
    "# Setup device\n",
    "# ===========================\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ===========================\n",
    "# Hugging Face Authentication\n",
    "# ===========================\n",
    "from huggingface_hub import login\n",
    "login(token = \"put your hugging face token here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:02.931835Z",
     "iopub.status.busy": "2025-09-18T14:46:02.931623Z",
     "iopub.status.idle": "2025-09-18T14:46:04.739283Z",
     "shell.execute_reply": "2025-09-18T14:46:04.738535Z",
     "shell.execute_reply.started": "2025-09-18T14:46:02.931818Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained encoders...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/speechbrain/utils/autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading pretrained encoders...\")\n",
    "language_id = EncoderClassifier.from_hparams(\n",
    "    source=\"TalTechNLP/voxlingua107-epaca-tdnn\",\n",
    "    savedir=\"tmp_lang\",\n",
    "    run_opts={\"device\": device}\n",
    ")\n",
    "\n",
    "speaker_id = EncoderClassifier.from_hparams(\n",
    "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
    "    savedir=\"tmp_spk\",\n",
    "    run_opts={\"device\": device}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:04.741109Z",
     "iopub.status.busy": "2025-09-18T14:46:04.740855Z",
     "iopub.status.idle": "2025-09-18T14:46:04.746032Z",
     "shell.execute_reply": "2025-09-18T14:46:04.745294Z",
     "shell.execute_reply.started": "2025-09-18T14:46:04.741089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Unfreeze encoder parameters for end-to-end training\n",
    "for param in language_id.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in speaker_id.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:04.747107Z",
     "iopub.status.busy": "2025-09-18T14:46:04.746868Z",
     "iopub.status.idle": "2025-09-18T14:46:04.761767Z",
     "shell.execute_reply": "2025-09-18T14:46:04.761105Z",
     "shell.execute_reply.started": "2025-09-18T14:46:04.747064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_lang_embedding(waveforms: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Extract language embeddings from waveforms\"\"\"\n",
    "    emb = language_id.encode_batch(waveforms.to(device))\n",
    "    return emb.squeeze(1).to(device)\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_spk_embeddings(waveforms: torch.Tensor, sr: int = 16000) -> torch.Tensor:\n",
    "    \"\"\"Extract speaker embeddings from waveforms\"\"\"\n",
    "    emb = speaker_id.encode_batch(waveforms.to(device))\n",
    "    return emb.squeeze(1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:04.763034Z",
     "iopub.status.busy": "2025-09-18T14:46:04.762534Z",
     "iopub.status.idle": "2025-09-18T14:46:04.777740Z",
     "shell.execute_reply": "2025-09-18T14:46:04.777245Z",
     "shell.execute_reply.started": "2025-09-18T14:46:04.763009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# CrossFeaturePrefixTuner\n",
    "# ===========================\n",
    "class CrossFeaturePrefixTuner(nn.Module):\n",
    "    def __init__(self, dim: int, num_heads: int = 4, prefix_len: int = 5):\n",
    "        super().__init__()\n",
    "        self.prefix_k = nn.Parameter(torch.randn(prefix_len, dim) * 0.02)\n",
    "        self.prefix_v = nn.Parameter(torch.randn(prefix_len, dim) * 0.02)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, query: torch.Tensor, kv: torch.Tensor) -> torch.Tensor:\n",
    "        B = kv.size(0)\n",
    "        prefix_k = self.prefix_k.unsqueeze(0).expand(B, -1, -1).to(kv.device)\n",
    "        prefix_v = self.prefix_v.unsqueeze(0).expand(B, -1, -1).to(kv.device)\n",
    "\n",
    "        k = torch.cat([prefix_k, kv], dim=1)\n",
    "        v = torch.cat([prefix_v, kv], dim=1)\n",
    "\n",
    "        out, _ = self.attn(query, k, v)\n",
    "        return out\n",
    "\n",
    "# ===========================\n",
    "# Sinusoidal Positional Encoding\n",
    "# ===========================\n",
    "def sinusoidal_pos_enc(seq_len: int, dim: int, device) -> torch.Tensor:\n",
    "    pe = torch.zeros(seq_len, dim, device=device)\n",
    "    position = torch.arange(0, seq_len, device=device).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, dim, 2, device=device) * (-math.log(10000.0) / dim))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:04.779175Z",
     "iopub.status.busy": "2025-09-18T14:46:04.778467Z",
     "iopub.status.idle": "2025-09-18T14:46:04.798204Z",
     "shell.execute_reply": "2025-09-18T14:46:04.797508Z",
     "shell.execute_reply.started": "2025-09-18T14:46:04.779150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# DecoderLSTMFCUp\n",
    "# ===========================\n",
    "class DecoderLSTMFCUp(nn.Module):\n",
    "    def __init__(self, embed_dim: int, n_mels: int = 80, hidden_dim: int = 512,\n",
    "                 lstm_layers: int = 2, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_mels = n_mels\n",
    "\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.LayerNorm(embed_dim),\n",
    "            nn.Linear(embed_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if lstm_layers > 1 else 0.0,\n",
    "            bidirectional=False,\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(hidden_dim, n_mels),\n",
    "        )\n",
    "\n",
    "        self.out_ln = nn.LayerNorm(n_mels)\n",
    "\n",
    "    def forward(self, query: torch.Tensor, out_len: int):\n",
    "        B, seq_len, _ = query.size()\n",
    "\n",
    "        # Adjust query length to match output length\n",
    "        if seq_len < out_len:\n",
    "            repeat_factor = (out_len + seq_len - 1) // seq_len\n",
    "            query = query.repeat(1, repeat_factor, 1)\n",
    "            query = query[:, :out_len, :]\n",
    "        elif seq_len > out_len:\n",
    "            query = query[:, :out_len, :]\n",
    "\n",
    "        x = self.pre(query)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.head(lstm_out)\n",
    "        out = self.out_ln(out)\n",
    "        return out\n",
    "\n",
    "# ===========================\n",
    "# AAM Softmax Loss (Additive Angular Margin)\n",
    "# ===========================\n",
    "class AAMSoftmax(nn.Module):\n",
    "    def __init__(self, n_classes, feat_dim, s=30.0, m=0.2):\n",
    "        super(AAMSoftmax, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.s = s  # Scale factor\n",
    "        self.m = m  # Margin\n",
    "\n",
    "        # Weight normalization\n",
    "        self.weight = nn.Parameter(torch.randn(n_classes, feat_dim))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        # Normalize features and weights\n",
    "        x_norm = F.normalize(x, p=2, dim=1)\n",
    "        w_norm = F.normalize(self.weight, p=2, dim=1)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        cosine = F.linear(x_norm, w_norm)\n",
    "\n",
    "        # Add margin to the target angle\n",
    "        phi = cosine - self.m\n",
    "\n",
    "        # One-hot encoding\n",
    "        one_hot = torch.zeros_like(cosine)\n",
    "        one_hot.scatter_(1, labels.view(-1, 1).long(), 1)\n",
    "\n",
    "        # Output with margin\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return F.cross_entropy(output, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:04.799614Z",
     "iopub.status.busy": "2025-09-18T14:46:04.798998Z",
     "iopub.status.idle": "2025-09-18T14:46:04.818621Z",
     "shell.execute_reply": "2025-09-18T14:46:04.817920Z",
     "shell.execute_reply.started": "2025-09-18T14:46:04.799588Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# LASPA Model\n",
    "# ===========================\n",
    "class LASPA(nn.Module):\n",
    "    def __init__(self, proj_dim: int = 192, num_heads: int = 4, prefix_len: int = 5,\n",
    "                 n_mels: int = 80, hidden_dim: int = 512, num_speakers: int = 1000,\n",
    "                 num_languages: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        # Projection layers\n",
    "        self.lang_proj_layer = nn.Linear(256, proj_dim)\n",
    "        self.spk_proj_layer = nn.Linear(192, proj_dim)  # Speaker embedding is 192-dim\n",
    "\n",
    "        # Cross-feature prefix tuners\n",
    "        self.spk2lang = CrossFeaturePrefixTuner(proj_dim, num_heads=num_heads, prefix_len=prefix_len)\n",
    "        self.lang2spk = CrossFeaturePrefixTuner(proj_dim, num_heads=num_heads, prefix_len=prefix_len)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = DecoderLSTMFCUp(embed_dim=2 * proj_dim, n_mels=n_mels, hidden_dim=hidden_dim)\n",
    "\n",
    "        # Mel spectrogram transform\n",
    "        self.mel_tf = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=16000,\n",
    "            n_fft=400,\n",
    "            win_length=400,\n",
    "            hop_length=160,\n",
    "            f_min=0.0,\n",
    "            f_max=8000.0,\n",
    "            n_mels=n_mels,\n",
    "            center=True,\n",
    "            pad_mode=\"reflect\",\n",
    "            power=2.0,\n",
    "            norm=None,\n",
    "            mel_scale=\"htk\"\n",
    "        ).to(device)  # Move to device\n",
    "\n",
    "        # Classification heads for AAM Softmax and NLL losses\n",
    "        self.speaker_classifier = AAMSoftmax(num_speakers, proj_dim, s=30.0, m=0.2)\n",
    "        self.language_classifier = nn.Linear(proj_dim, num_languages)\n",
    "\n",
    "    @staticmethod\n",
    "    def _log_mel(mel: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
    "        return torch.log(mel + eps)\n",
    "\n",
    "    def forward(self, waveforms: torch.Tensor, speaker_ids=None, language_ids=None):\n",
    "        B = waveforms.size(0)\n",
    "\n",
    "        # Get embeddings\n",
    "        with torch.no_grad():\n",
    "            spk_raw = get_spk_embeddings(waveforms)\n",
    "            lang_raw = get_lang_embedding(waveforms)\n",
    "\n",
    "        # Project embeddings\n",
    "        spk_proj = self.spk_proj_layer(spk_raw)\n",
    "        lang_proj = self.lang_proj_layer(lang_raw)\n",
    "\n",
    "        # Prepare for cross-attention\n",
    "        spk_q = spk_proj.unsqueeze(1)\n",
    "        lang_q = lang_proj.unsqueeze(1)\n",
    "\n",
    "        # Cross-feature fusion\n",
    "        spk2lang_out = self.spk2lang(spk_q, lang_q)\n",
    "        lang2spk_out = self.lang2spk(lang_q, spk_q)\n",
    "\n",
    "        # Concatenate fused features\n",
    "        fused = torch.cat([spk2lang_out, lang2spk_out], dim=-1)\n",
    "\n",
    "        # Generate mel spectrogram target\n",
    "        with torch.no_grad():\n",
    "            mel = self.mel_tf(waveforms.to(device))\n",
    "            mel = self._log_mel(mel)\n",
    "            mel_target = mel.transpose(1, 2)\n",
    "\n",
    "        out_len = mel_target.size(1)\n",
    "\n",
    "        # Decode to mel spectrogram\n",
    "        mel_hat = self.decoder(fused, out_len=out_len)\n",
    "\n",
    "        # Compute classification logits for losses\n",
    "        speaker_loss = None\n",
    "        language_logits = None\n",
    "\n",
    "        if speaker_ids is not None:\n",
    "            speaker_loss = self.speaker_classifier(spk_proj, speaker_ids)\n",
    "\n",
    "        if language_ids is not None:\n",
    "            language_logits = self.language_classifier(lang_proj)\n",
    "\n",
    "        return mel_hat, mel_target, spk_proj, lang_proj, speaker_loss, language_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:04.821052Z",
     "iopub.status.busy": "2025-09-18T14:46:04.820680Z",
     "iopub.status.idle": "2025-09-18T14:46:04.836568Z",
     "shell.execute_reply": "2025-09-18T14:46:04.836051Z",
     "shell.execute_reply.started": "2025-09-18T14:46:04.821036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Loss Functions\n",
    "# ===========================\n",
    "def compute_lmse(recon: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Mean Squared Error Loss for mel spectrogram reconstruction\"\"\"\n",
    "    return F.mse_loss(recon, target)\n",
    "\n",
    "def compute_lmapc(spk_emb: torch.Tensor, lang_emb: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Mean Absolute Pearson Correlation loss for disentanglement\"\"\"\n",
    "    spk = spk_emb - spk_emb.mean(dim=-1, keepdim=True)\n",
    "    lang = lang_emb - lang_emb.mean(dim=-1, keepdim=True)\n",
    "\n",
    "    num = (spk * lang).sum(dim=-1)\n",
    "    den = torch.norm(spk, dim=-1) * torch.norm(lang, dim=-1) + 1e-8\n",
    "    corr = num / den\n",
    "\n",
    "    return corr.abs().mean()  # Return absolute correlation (want to minimize)\n",
    "\n",
    "class LASPALoss(nn.Module):\n",
    "    def __init__(self, alpha: float = 1.0, beta: float = 1.0, gamma: float = 1.0, delta: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor(alpha))  # MSE weight\n",
    "        self.beta = nn.Parameter(torch.tensor(beta))    # MAPC weight\n",
    "        self.gamma = nn.Parameter(torch.tensor(gamma))  # AAM Softmax weight\n",
    "        self.delta = nn.Parameter(torch.tensor(delta))  # NLL weight\n",
    "\n",
    "    def forward(self, mel_hat, mel_target, spk_emb, lang_emb, speaker_loss, language_logits, language_ids):\n",
    "        # MSE Loss for reconstruction\n",
    "        lmse = compute_lmse(mel_hat, mel_target)\n",
    "\n",
    "        # MAPC Loss for disentanglement\n",
    "        lmapc = compute_lmapc(spk_emb, lang_emb)\n",
    "\n",
    "        # Initialize classification losses\n",
    "        aam_loss = torch.tensor(0.0, device=mel_hat.device)\n",
    "        nll_loss = torch.tensor(0.0, device=mel_hat.device)\n",
    "\n",
    "        # AAM Softmax Loss (already computed in model)\n",
    "        if speaker_loss is not None:\n",
    "            aam_loss = speaker_loss\n",
    "\n",
    "        # NLL Loss for language classification\n",
    "        if language_logits is not None and language_ids is not None:\n",
    "            nll_loss = F.cross_entropy(language_logits, language_ids)\n",
    "\n",
    "        # Total weighted loss\n",
    "        total = self.alpha * lmse + self.beta * lmapc + self.gamma * aam_loss + self.delta * nll_loss\n",
    "\n",
    "        metrics = {\n",
    "            \"LMSE\": float(lmse.detach().cpu()),\n",
    "            \"LMAPC\": float(lmapc.detach().cpu()),\n",
    "            \"AAM\": float(aam_loss.detach().cpu()),\n",
    "            \"NLL\": float(nll_loss.detach().cpu())\n",
    "        }\n",
    "\n",
    "        return total, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:04.837505Z",
     "iopub.status.busy": "2025-09-18T14:46:04.837276Z",
     "iopub.status.idle": "2025-09-18T14:46:04.858039Z",
     "shell.execute_reply": "2025-09-18T14:46:04.857447Z",
     "shell.execute_reply.started": "2025-09-18T14:46:04.837480Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torchaudio\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------\n",
    "# Kathbath Dataset (non-streaming)\n",
    "# -------------------------------\n",
    "class KathbathDataset(Dataset):\n",
    "    def __init__(self, languages=[\"sanskrit\"], split=\"train\", max_samples_per_lang=None, target_sr=16000):\n",
    "        super().__init__()\n",
    "        self.languages = languages\n",
    "        self.split = split\n",
    "        self.target_sr = target_sr\n",
    "        self.data = []\n",
    "        \n",
    "        # Global mappings\n",
    "        self.speaker_to_id = {}\n",
    "        self.language_to_id = {lang: i for i, lang in enumerate(languages)}\n",
    "        self.lang_speakers = {lang: set() for lang in languages}\n",
    "\n",
    "        # Load datasets fully\n",
    "        for lang in languages:\n",
    "            try:\n",
    "                ds = load_dataset(\"ai4bharat/Kathbath\", lang, split=split)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load {lang} dataset: {e}\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Loading {lang} samples...\")\n",
    "            for i, item in enumerate(tqdm(ds, ncols=100)):\n",
    "                if max_samples_per_lang and i >= max_samples_per_lang:\n",
    "                    break\n",
    "\n",
    "                audio = item.get(\"audio_filepath\", None)\n",
    "                if audio is None or \"array\" not in audio:\n",
    "                    continue\n",
    "\n",
    "                speaker = item.get(\"speaker_id\", f\"{lang}_unk\")\n",
    "                if speaker not in self.speaker_to_id:\n",
    "                    self.speaker_to_id[speaker] = len(self.speaker_to_id)\n",
    "                self.lang_speakers[lang].add(speaker)\n",
    "\n",
    "                waveform = torch.tensor(audio[\"array\"]).float()\n",
    "                sr = audio[\"sampling_rate\"]\n",
    "                if sr != self.target_sr:\n",
    "                    waveform = torchaudio.transforms.Resample(sr, self.target_sr)(waveform)\n",
    "\n",
    "                self.data.append({\n",
    "                    \"waveform\": waveform,\n",
    "                    \"speaker_id\": self.speaker_to_id[speaker],\n",
    "                    \"language_id\": self.language_to_id[lang]\n",
    "                })\n",
    "\n",
    "        if len(self.data) == 0:\n",
    "            print(\"Warning: No valid samples found!\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# -------------------------------\n",
    "# Collate function\n",
    "# -------------------------------\n",
    "def collate_fn(batch):\n",
    "    max_len = max(x[\"waveform\"].shape[0] for x in batch)\n",
    "    waveforms, speakers, langs = [], [], []\n",
    "\n",
    "    for x in batch:\n",
    "        wf = x[\"waveform\"]\n",
    "        if wf.shape[0] < max_len:\n",
    "            wf = F.pad(wf, (0, max_len - wf.shape[0]))\n",
    "        else:\n",
    "            wf = wf[:max_len]\n",
    "        waveforms.append(wf)\n",
    "        speakers.append(x[\"speaker_id\"])\n",
    "        langs.append(x[\"language_id\"])\n",
    "\n",
    "    return {\n",
    "        \"waveform\": torch.stack(waveforms),\n",
    "        \"speaker_id\": torch.tensor(speakers, dtype=torch.long),\n",
    "        \"language_id\": torch.tensor(langs, dtype=torch.long),\n",
    "    }\n",
    "\n",
    "# -------------------------------\n",
    "# Setup DataLoader\n",
    "# -------------------------------\n",
    "def setup_dataloader(langs=[\"sanskrit\"], split=\"train\", batch_size=4, max_samples_per_lang=None):\n",
    "    dataset = KathbathDataset(languages=langs, split=split, max_samples_per_lang=max_samples_per_lang)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True, num_workers=0)\n",
    "\n",
    "    print(f\"\\nTotal samples: {len(dataset)}\")\n",
    "    print(f\"Total Speakers: {len(dataset.speaker_to_id)}, Total Languages: {len(dataset.language_to_id)}\")\n",
    "    for lang in langs:\n",
    "        print(f\"  {lang}: {len(dataset.lang_speakers[lang])} speakers\")\n",
    "\n",
    "    return dataloader, len(dataset.speaker_to_id), len(dataset.language_to_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:04.858820Z",
     "iopub.status.busy": "2025-09-18T14:46:04.858657Z",
     "iopub.status.idle": "2025-09-18T14:46:05.268578Z",
     "shell.execute_reply": "2025-09-18T14:46:05.267924Z",
     "shell.execute_reply.started": "2025-09-18T14:46:04.858808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "@torch.no_grad()\n",
    "def visualize_embeddings(model, dataloader, max_batches=5):\n",
    "    all_spk, all_lang, all_spk_id, all_lang_id = [], [], [], []\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i >= max_batches: break\n",
    "        wave = batch[\"waveform\"].to(device)\n",
    "        spk_id = batch[\"speaker_id\"].cpu().numpy()\n",
    "        lang_id = batch[\"language_id\"].cpu().numpy()\n",
    "\n",
    "        _, _, spk_emb, lang_emb, _, _ = model(wave)\n",
    "\n",
    "        all_spk.append(spk_emb.cpu())\n",
    "        all_lang.append(lang_emb.cpu())\n",
    "        all_spk_id.extend(spk_id)\n",
    "        all_lang_id.extend(lang_id)\n",
    "\n",
    "    spk_mat = torch.cat(all_spk).numpy()\n",
    "    lang_mat = torch.cat(all_lang).numpy()\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    spk_2d = tsne.fit_transform(spk_mat)\n",
    "    lang_2d = tsne.fit_transform(lang_mat)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(spk_2d[:,0], spk_2d[:,1], c=all_spk_id, cmap=\"tab20\", s=10)\n",
    "    plt.title(\"Speaker Embeddings\")\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(lang_2d[:,0], lang_2d[:,1], c=all_lang_id, cmap=\"tab10\", s=10)\n",
    "    plt.title(\"Language Embeddings\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:05.269471Z",
     "iopub.status.busy": "2025-09-18T14:46:05.269291Z",
     "iopub.status.idle": "2025-09-18T14:46:05.274138Z",
     "shell.execute_reply": "2025-09-18T14:46:05.273413Z",
     "shell.execute_reply.started": "2025-09-18T14:46:05.269456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_mel_comparison(mel_true, mel_recon, idx=0):\n",
    "    fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "    axes[0].imshow(mel_true[idx].T.cpu().numpy(), aspect=\"auto\", origin=\"lower\")\n",
    "    axes[0].set_title(\"Ground Truth Mel\")\n",
    "    axes[1].imshow(mel_recon[idx].T.detach().cpu().numpy(), aspect=\"auto\", origin=\"lower\")\n",
    "    axes[1].set_title(\"Reconstructed Mel\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:05.275224Z",
     "iopub.status.busy": "2025-09-18T14:46:05.274968Z",
     "iopub.status.idle": "2025-09-18T14:46:05.291535Z",
     "shell.execute_reply": "2025-09-18T14:46:05.290803Z",
     "shell.execute_reply.started": "2025-09-18T14:46:05.275196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Training Loop\n",
    "# ===========================\n",
    "def training_loop(model, loss_fn, optimizer, scheduler, train_loader, num_epochs=5):\n",
    "    print(\"Starting training...\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_lmse = 0.0\n",
    "        total_lmapc = 0.0\n",
    "        total_aam = 0.0\n",
    "        total_nll = 0.0\n",
    "        num_batches = 0\n",
    "\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            try:\n",
    "                # Move data to device\n",
    "                waveforms = batch['waveform'].to(device)\n",
    "                speaker_ids = batch['speaker_id'].to(device)\n",
    "                language_ids = batch['language_id'].to(device)\n",
    "\n",
    "                # Zero gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                mel_hat, mel_target, spk_emb, lang_emb, speaker_loss, language_logits = model(\n",
    "                    waveforms, speaker_ids, language_ids\n",
    "                )\n",
    "\n",
    "                # Compute loss\n",
    "                loss, metrics = loss_fn(\n",
    "                    mel_hat, mel_target, spk_emb, lang_emb,\n",
    "                    speaker_loss, language_logits, language_ids\n",
    "                )\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "                # Update weights\n",
    "                optimizer.step()\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_lmse += metrics[\"LMSE\"]\n",
    "                total_lmapc += metrics[\"LMAPC\"]\n",
    "                total_aam += metrics[\"AAM\"]\n",
    "                total_nll += metrics[\"NLL\"]\n",
    "                num_batches += 1\n",
    "\n",
    "                # Print progress\n",
    "                if batch_idx % 5 == 0:\n",
    "                        print(f\"Epoch {epoch}, Batch {batch_idx+1}\")  # <-- remove len(train_loader)\n",
    "                        print(f\"  Loss: {loss.item():.4f}\")\n",
    "                        print(f\"  LMSE: {metrics['LMSE']:.4f}, LMAPC: {metrics['LMAPC']:.4f}\")\n",
    "                        print(f\"  AAM: {metrics['AAM']:.4f}, NLL: {metrics['NLL']:.4f}\")\n",
    "\n",
    "                # Early stopping for quick testing (remove this for full training)\n",
    "                if batch_idx >= 10:  # Just 10 batches per epoch for initial testing\n",
    "                    break\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in batch {batch_idx}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "        if num_batches > 0:\n",
    "            avg_loss = total_loss / num_batches\n",
    "            avg_lmse = total_lmse / num_batches\n",
    "            avg_lmapc = total_lmapc / num_batches\n",
    "            avg_aam = total_aam / num_batches\n",
    "            avg_nll = total_nll / num_batches\n",
    "\n",
    "            # Update learning rate\n",
    "            scheduler.step(avg_loss)\n",
    "\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Epoch {epoch} Summary:\")\n",
    "            print(f\"  Avg Loss: {avg_loss:.4f}\")\n",
    "            print(f\"  Avg LMSE: {avg_lmse:.4f}, Avg LMAPC: {avg_lmapc:.4f}\")\n",
    "            print(f\"  Avg AAM: {avg_aam:.4f}, Avg NLL: {avg_nll:.4f}\")\n",
    "            print(f\"  Loss weights - α: {loss_fn.alpha.item():.4f}, β: {loss_fn.beta.item():.4f}\")\n",
    "            print(f\"                γ: {loss_fn.gamma.item():.4f}, δ: {loss_fn.delta.item():.4f}\")\n",
    "            print(f\"  Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "            print(f\"{'='*50}\\n\")\n",
    "\n",
    "            # Save checkpoint every epoch\n",
    "            save_checkpoint(epoch, model, optimizer, loss_fn, avg_loss)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:05.292608Z",
     "iopub.status.busy": "2025-09-18T14:46:05.292364Z",
     "iopub.status.idle": "2025-09-18T14:46:05.310098Z",
     "shell.execute_reply": "2025-09-18T14:46:05.309378Z",
     "shell.execute_reply.started": "2025-09-18T14:46:05.292583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Utility Functions\n",
    "# ===========================\n",
    "def save_checkpoint(epoch, model, optimizer, loss_fn, avg_loss):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss_fn_state_dict': loss_fn.state_dict(),\n",
    "        'avg_loss': avg_loss,\n",
    "    }\n",
    "    torch.save(checkpoint, f'laspa_checkpoint_epoch_{epoch}.pth')\n",
    "    print(f\"Saved checkpoint at epoch {epoch}\")\n",
    "\n",
    "def save_final_model(model):\n",
    "    torch.save(model.state_dict(), 'laspa_final_model.pth')\n",
    "    print(\"Final model saved as 'laspa_final_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:05.311145Z",
     "iopub.status.busy": "2025-09-18T14:46:05.310865Z",
     "iopub.status.idle": "2025-09-18T14:46:05.329674Z",
     "shell.execute_reply": "2025-09-18T14:46:05.328871Z",
     "shell.execute_reply.started": "2025-09-18T14:46:05.311121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def setup_model_and_optimizer(num_speakers, num_languages, device=device, lr=1e-3):\n",
    "    # Initialize model\n",
    "    model = LASPA(num_speakers=num_speakers, num_languages=num_languages).to(device)\n",
    "\n",
    "    # Loss function\n",
    "    loss_fn = LASPALoss(alpha=1.0, beta=1.0, gamma=1.0, delta=1.0).to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=1)\n",
    "\n",
    "    return model, loss_fn, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:05.332287Z",
     "iopub.status.busy": "2025-09-18T14:46:05.331518Z",
     "iopub.status.idle": "2025-09-18T14:46:05.346689Z",
     "shell.execute_reply": "2025-09-18T14:46:05.346084Z",
     "shell.execute_reply.started": "2025-09-18T14:46:05.332266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Main Training Function\n",
    "# ===========================\n",
    "def train_laspa():\n",
    "    \"\"\"Main function to orchestrate the entire training process\"\"\"\n",
    "    try:\n",
    "        # Setup data\n",
    "        train_loader, num_speakers, num_languages = setup_dataloader()\n",
    "\n",
    "        # Setup model and training components\n",
    "        model, loss_fn, optimizer, scheduler = setup_model_and_optimizer(\n",
    "            num_speakers, num_languages\n",
    "        )\n",
    "\n",
    "        # Print model info\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"\\nModel Information:\")\n",
    "        print(f\"Total parameters: {total_params:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "        # Train the model\n",
    "        model = training_loop(model, loss_fn, optimizer, scheduler, train_loader, num_epochs=5)\n",
    "\n",
    "        # Save final model\n",
    "        save_final_model(model)\n",
    "\n",
    "        print(\"\\nTraining completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-18T14:46:08.998869Z",
     "iopub.status.busy": "2025-09-18T14:46:08.998120Z",
     "iopub.status.idle": "2025-09-18T14:49:29.914015Z",
     "shell.execute_reply": "2025-09-18T14:49:29.913250Z",
     "shell.execute_reply.started": "2025-09-18T14:46:08.998844Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd64a698f9e43c38eafc84899ed5c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5d331e26d4456aa954e561433999fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3ac4b8653c44fc8ef463800b973a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sanskrit samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 26840/26840 [02:53<00:00, 154.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total samples: 26840\n",
      "Total Speakers: 182, Total Languages: 1\n",
      "  sanskrit: 182 speakers\n",
      "\n",
      "Model Information:\n",
      "Total parameters: 5,126,065\n",
      "Trainable parameters: 5,126,065\n",
      "Starting training...\n",
      "Epoch 1, Batch 1\n",
      "  Loss: 98.1440\n",
      "  LMSE: 82.4190, LMAPC: 0.0689\n",
      "  AAM: 15.6561, NLL: 0.0000\n",
      "Epoch 1, Batch 6\n",
      "  Loss: 103.7782\n",
      "  LMSE: 91.9563, LMAPC: 0.0545\n",
      "  AAM: 11.7674, NLL: 0.0000\n",
      "Epoch 1, Batch 11\n",
      "  Loss: 81.3836\n",
      "  LMSE: 72.3105, LMAPC: 0.0989\n",
      "  AAM: 8.9742, NLL: 0.0000\n",
      "\n",
      "==================================================\n",
      "Epoch 1 Summary:\n",
      "  Avg Loss: 101.1970\n",
      "  Avg LMSE: 89.5106, Avg LMAPC: 0.0707\n",
      "  Avg AAM: 11.6157, Avg NLL: 0.0000\n",
      "  Loss weights - α: 1.0000, β: 1.0000\n",
      "                γ: 1.0000, δ: 1.0000\n",
      "  Learning rate: 0.001000\n",
      "==================================================\n",
      "\n",
      "Saved checkpoint at epoch 1\n",
      "Epoch 2, Batch 1\n",
      "  Loss: 93.5003\n",
      "  LMSE: 78.1308, LMAPC: 0.0165\n",
      "  AAM: 15.3530, NLL: 0.0000\n",
      "Epoch 2, Batch 6\n",
      "  Loss: 100.7049\n",
      "  LMSE: 86.9921, LMAPC: 0.0469\n",
      "  AAM: 13.6659, NLL: 0.0000\n",
      "Epoch 2, Batch 11\n",
      "  Loss: 84.6595\n",
      "  LMSE: 73.5715, LMAPC: 0.0419\n",
      "  AAM: 11.0461, NLL: 0.0000\n",
      "\n",
      "==================================================\n",
      "Epoch 2 Summary:\n",
      "  Avg Loss: 98.1920\n",
      "  Avg LMSE: 86.7647, Avg LMAPC: 0.0519\n",
      "  Avg AAM: 11.3754, Avg NLL: 0.0000\n",
      "  Loss weights - α: 1.0000, β: 1.0000\n",
      "                γ: 1.0000, δ: 1.0000\n",
      "  Learning rate: 0.001000\n",
      "==================================================\n",
      "\n",
      "Saved checkpoint at epoch 2\n",
      "Epoch 3, Batch 1\n",
      "  Loss: 113.0796\n",
      "  LMSE: 97.7262, LMAPC: 0.0409\n",
      "  AAM: 15.3125, NLL: 0.0000\n",
      "Epoch 3, Batch 6\n",
      "  Loss: 96.0449\n",
      "  LMSE: 86.1701, LMAPC: 0.0412\n",
      "  AAM: 9.8335, NLL: 0.0000\n",
      "Epoch 3, Batch 11\n",
      "  Loss: 80.1649\n",
      "  LMSE: 72.3633, LMAPC: 0.0182\n",
      "  AAM: 7.7834, NLL: 0.0000\n",
      "\n",
      "==================================================\n",
      "Epoch 3 Summary:\n",
      "  Avg Loss: 106.2749\n",
      "  Avg LMSE: 96.4897, Avg LMAPC: 0.0451\n",
      "  Avg AAM: 9.7402, Avg NLL: 0.0000\n",
      "  Loss weights - α: 1.0000, β: 1.0000\n",
      "                γ: 1.0000, δ: 1.0000\n",
      "  Learning rate: 0.001000\n",
      "==================================================\n",
      "\n",
      "Saved checkpoint at epoch 3\n",
      "Epoch 4, Batch 1\n",
      "  Loss: 107.0705\n",
      "  LMSE: 97.1126, LMAPC: 0.0564\n",
      "  AAM: 9.9016, NLL: 0.0000\n",
      "Epoch 4, Batch 6\n",
      "  Loss: 63.9977\n",
      "  LMSE: 55.5137, LMAPC: 0.0663\n",
      "  AAM: 8.4177, NLL: 0.0000\n",
      "Epoch 4, Batch 11\n",
      "  Loss: 94.5171\n",
      "  LMSE: 84.0357, LMAPC: 0.0620\n",
      "  AAM: 10.4193, NLL: 0.0000\n",
      "\n",
      "==================================================\n",
      "Epoch 4 Summary:\n",
      "  Avg Loss: 98.1230\n",
      "  Avg LMSE: 90.2494, Avg LMAPC: 0.0405\n",
      "  Avg AAM: 7.8331, Avg NLL: 0.0000\n",
      "  Loss weights - α: 1.0000, β: 1.0000\n",
      "                γ: 1.0000, δ: 1.0000\n",
      "  Learning rate: 0.001000\n",
      "==================================================\n",
      "\n",
      "Saved checkpoint at epoch 4\n",
      "Epoch 5, Batch 1\n",
      "  Loss: 77.3441\n",
      "  LMSE: 68.6621, LMAPC: 0.0221\n",
      "  AAM: 8.6598, NLL: 0.0000\n",
      "Epoch 5, Batch 6\n",
      "  Loss: 78.5732\n",
      "  LMSE: 65.8210, LMAPC: 0.0500\n",
      "  AAM: 12.7023, NLL: 0.0000\n",
      "Epoch 5, Batch 11\n",
      "  Loss: 87.6137\n",
      "  LMSE: 83.3514, LMAPC: 0.0556\n",
      "  AAM: 4.2067, NLL: 0.0000\n",
      "\n",
      "==================================================\n",
      "Epoch 5 Summary:\n",
      "  Avg Loss: 96.7240\n",
      "  Avg LMSE: 88.4257, Avg LMAPC: 0.0363\n",
      "  Avg AAM: 8.2619, Avg NLL: 0.0000\n",
      "  Loss weights - α: 1.0000, β: 1.0000\n",
      "                γ: 1.0000, δ: 1.0000\n",
      "  Learning rate: 0.001000\n",
      "==================================================\n",
      "\n",
      "Saved checkpoint at epoch 5\n",
      "Final model saved as 'laspa_final_model.pth'\n",
      "\n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# Execute Training\n",
    "# ===========================\n",
    "if __name__ == \"__main__\":\n",
    "    train_laspa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
